#

## 2017/11/06
* [SNAPSHOT ENSEMBLES: TRAIN 1, GET M FOR FREE](https://arxiv.org/pdf/1704.00109.pdf)
* [A Survey of Model Compression and Acceleration for Deep Neural Networks](https://arxiv.org/pdf/1710.09282.pdf)* [A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs](http://science.sciencemag.org/content/early/2017/10/25/science.aag2612/tab-pdf)
* [An Empirical Study of Language CNN for Image Captioning](https://arxiv.org/pdf/1612.07086.pdf)
* [Neural Encoding and Decoding with Deep Learning for Dynamic Natural Vision](https://arxiv.org/ftp/arxiv/papers/1608/1608.03425.pdf)
* [DON’T DECAY THE LEARNING RATE, INCREASE THE BATCH SIZE](https://arxiv.org/pdf/1711.00489.pdf)
* [A systematic study of the class imbalance problem in convolutional neural networks](https://arxiv.org/pdf/1710.05381.pdf)
* [Logistic Regression in Rare Events Data](https://gking.harvard.edu/files/0s.pdf)

* [DSSD : Deconvolutional Single Shot Detector](https://arxiv.org/pdf/1701.06659.pdf)

* [AdaDNNs: Adaptive Ensemble of Deep Neural Networks　for Scene Text Recognition](https://arxiv.org/pdf/1710.03425v1.pdf)

* [Focal Loss for Dense Object Detection](https://arxiv.org/pdf/1708.02002.pdf)
* [Flexible Rectified Linear Units for Improving Convolutional Neural Networks](https://arxiv.org/pdf/1706.08098.pdf)

* [The One Hundred Layers Tiramisu:Fully Convolutional DenseNets for Semantic Segmentation](https://arxiv.org/pdf/1611.09326.pdf)

## 2017/11/09
* [Fully-Parallel Text Generation for Neural Machine Translation](https://einstein.ai/research/non-autoregressive-neural-machine-translation)
* [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf)
* [A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs](http://science.sciencemag.org/content/early/2017/10/25/science.aag2612/tab-pdf)
* [Variational Walkback: Learning a Transition
Operator as a Stochastic Recurrent Net](https://arxiv.org/pdf/1711.02282.pdf)

## 2017/11/16
* [An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition](https://arxiv.org/pdf/1507.05717.pdf)

## 2017/11/17
* [Deep Speech 2: End-to-End Speech Recognition in English and Mandarin](https://arxiv.org/pdf/1512.02595.pdf)

## 2017/11/21
* [Robust Scene Text Recognition with Automatic Rectification](https://arxiv.org/pdf/1603.03915.pdf)
* [Recursive Recurrent Nets with Attention Modeling for OCR in the Wild](https://arxiv.org/pdf/1603.03101.pdf)

## 2017/11/29
* [Population Based Training of Neural Networks](https://arxiv.org/pdf/1711.09846.pdf)
(https://deepmind.com/blog/population-based-training-neural-networks/)
* [How to Develop an Encoder-Decoder Model with Attention for Sequence-to-Sequence Prediction in Keras](https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/)
* [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)
* [Attention in Long Short-Term Memory Recurrent Neural Networks](https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/)
* [How Does Attention Work in Encoder-Decoder Recurrent Neural Networks](https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/)

## 2017/11/30
* [CondenseNet: An Efficient DenseNet using Learned Group Convolutions](https://arxiv.org/pdf/1711.09224.pdf)
